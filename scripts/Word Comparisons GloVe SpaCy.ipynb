{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import matplotlib.ticker as ticker\n",
    "import urllib\n",
    "import sys\n",
    "import os\n",
    "import zipfile\n",
    "#import glove\n",
    "import spacy\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import comparison_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 most similar words to illegals :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['immigrants',\n",
       " 'undocumented',\n",
       " 'deport',\n",
       " 'immigration',\n",
       " 'lawbreakers',\n",
       " 'criminals',\n",
       " 'non-citizens',\n",
       " 'deporting',\n",
       " 'amnesty',\n",
       " 'felons',\n",
       " 'illegal',\n",
       " 'freeloaders',\n",
       " 'migrants',\n",
       " 'aliens',\n",
       " 'hispanics',\n",
       " 'foreigners',\n",
       " 'deported',\n",
       " 'immigrant',\n",
       " 'mexicans',\n",
       " 'non-whites']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word vector similarities \n",
    "parser = spacy.load('en_core_web_lg')\n",
    "word = parser.vocab[u'illegals']\n",
    "\n",
    "comparison_functions.similar_strings(parser,word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word pair similarities\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "Noncitizen = (u'illegals undocumented refugees immigrants foreigners') #list of strings = input at present\n",
    "Citizen = (u'citizens inhabitants locals natives residents') #list of strings = input at present\n",
    "# removed for graphing purposes, but still include in analysis [foreigners deportees nationalist]\n",
    "#w = (u'Mexican Iranian Afghanistan European Syrian Chinese Iraqi Egyptian Yemenese American ')\n",
    "Good = (u'sincere honest trustworthy share nice')\n",
    "Bad = (u'sneaky deceitful mean rude careless')\n",
    "#z = (u'honest deceptive devious dishonest steal give share sneak hide cheat sincere smart dumb') #hide steal cheat (criminal, visiblity) #sincere\n",
    "results_citizen_good = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, Citizen, Good)\n",
    "results_citizen_bad = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, Citizen, Bad)\n",
    "\n",
    "results_noncitizen_good = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, Noncitizen, Good)\n",
    "results_noncitizen_bad = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, Noncitizen, Bad)\n",
    "\n",
    "results_within_citizen = comparison_functions.Compare_Within_WordList_by_spaCyvectors(nlp, Citizen)\n",
    "results_within_noncitizen = comparison_functions.Compare_Within_WordList_by_spaCyvectors(nlp, Noncitizen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[citizens, sincere, 0.33278966]\n",
      "[citizens, honest, 0.39526188]\n",
      "[citizens, trustworthy, 0.28800914]\n",
      "[citizens, share, 0.3022199]\n",
      "[citizens, nice, 0.12876624]\n",
      "[inhabitants, sincere, 0.16663435]\n",
      "[inhabitants, honest, 0.14875652]\n",
      "[inhabitants, trustworthy, 0.12388269]\n",
      "[inhabitants, share, 0.21494235]\n",
      "[inhabitants, nice, 0.070753]\n",
      "[locals, sincere, 0.22092831]\n",
      "[locals, honest, 0.3029389]\n",
      "[locals, trustworthy, 0.20988159]\n",
      "[locals, share, 0.28886786]\n",
      "[locals, nice, 0.31843078]\n",
      "[natives, sincere, 0.20599838]\n",
      "[natives, honest, 0.1913316]\n",
      "[natives, trustworthy, 0.110087916]\n",
      "[natives, share, 0.19138527]\n",
      "[natives, nice, 0.12230251]\n",
      "[residents, sincere, 0.17513339]\n",
      "[residents, honest, 0.20379253]\n",
      "[residents, trustworthy, 0.13388737]\n",
      "[residents, share, 0.3325569]\n",
      "[residents, nice, 0.11550475]\n"
     ]
    }
   ],
   "source": [
    "#for row in results_within_noncitizen: \n",
    "#    print(row)\n",
    "for row in results_citizen_good: \n",
    "    print(row)\n",
    "#for row in results_within_y: \n",
    "#    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#saving word pairs and corresponding similarity scores dataframe as csv\n",
    "\n",
    "pd.DataFrame(results_citizen_good).to_csv('results_citizen_good.csv')\n",
    "pd.DataFrame(results_citizen_bad).to_csv('results_citizen_bad.csv')\n",
    "pd.DataFrame(results_noncitizen_good).to_csv('results_noncitizen_good.csv')\n",
    "pd.DataFrame(results_noncitizen_bad).to_csv('results_noncitizen_bad.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##replication of Bryson Science\n",
    "\n",
    "#Flowers: aster, clover, hyacinth, marigold, poppy, azalea, crocus, iris, orchid, rose, bluebell, daffodil, lilac, pansy, tulip, buttercup, daisy, lily, peony, violet, carnation, gladiola, magnolia, petunia, zinnia.\n",
    "#Insects: ant, caterpillar, flea, locust, spider, bedbug, centipede, fly, maggot, tarantula, bee, cockroach, gnat, mosquito, termite, beetle, cricket, hornet, moth, wasp, blackfly, dragonfly, horsefly, roach, weevil.\n",
    "#Pleasant: caress, freedom, health, love, peace, cheer, friend, heaven, loyal, pleasure, diamond, gentle, honest, lucky, rainbow, diploma, gift, honor, miracle, sunrise, family, happy, laughter, paradise, vacation.\n",
    "#Unpleasant: abuse, crash, filth, murder, sickness, accident, death, grief, poison, stink, assault, disaster, hatred, pollute, tragedy, divorce, jail, poverty, ugly, cancer, kill, rotten, vomit, agony, prison\n",
    "\n",
    "\n",
    "##word similarity scores \n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "Flowers = (u'aster clover hyacinth marigold poppy azalea crocus iris orchid rose bluebell daffodil lilac pansy tulip buttercup daisy lily peony violet carnation gladiola magnolia petunia zinnia') #list of strings = input at present\n",
    "Insects = (u'ant caterpillar flea locust spider bedbug centipede fly maggot tarantula bee cockroach gnat mosquito termite beetle cricket hornet moth wasp blackfly dragonfly horsefly roach weevil')\n",
    "Pleasant = (u'caress freedom health love peace cheer friend heaven loyal pleasure diamond gentle honest lucky rainbow diploma gift honor miracle sunrise family happy laughter paradise vacation')\n",
    "Unpleasant = (u'abuse crash filth murder sickness accident death grief poison stink assault disaster hatred pollute tragedy divorce jail poverty ugly cancer kill rotten vomit agony prison')\n",
    "\n",
    "results_across_grpFp = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, Flowers, Pleasant)\n",
    "results_across_grpFu = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, Flowers, Unpleasant)\n",
    "\n",
    "results_across_grpIp = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, Insects, Pleasant)\n",
    "results_across_grpIu = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, Insects, Unpleasant)\n",
    "\n",
    "\n",
    "#results_within_x = comparison_functions.Compare_Within_WordList_by_spaCyvectors(nlp, x)\n",
    "#results_within_y = comparison_functions.Compare_Within_WordList_by_spaCyvectors(nlp, w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d8a8aadb26d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults_across_grpFp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "for row in results_across_grpFp: \n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e470b4307012>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults_across_grpFu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "for row in results_across_grpFu: \n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#results_across_grpFp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving word pairs and corresponding similarity scores dataframe as csv\n",
    "\n",
    "pd.DataFrame(results_across_grpFp).to_csv('results_across_grpFp.csv')\n",
    "pd.DataFrame(results_across_grpFu).to_csv('results_across_grpFu.csv')\n",
    "pd.DataFrame(results_across_grpIp).to_csv('results_across_grpIp.csv')\n",
    "pd.DataFrame(results_across_grpIu).to_csv('results_across_grpIu.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##replication: vanderbilt names\n",
    "#word pair similarities\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "latino_names = (u'Garcia Martinez Rodriguez Lopez Hernandez Gonzalez Perez Sanchez Diaz Ramirez') #list of strings = input at present\n",
    "white_names = (u'Smith Johnson Williams Jones Brown Davis Miller Wilson Moore Taylor')\n",
    "Good = (u'honest joy love peace wonderful honor pleasure glorious laughter happy')\n",
    "Bad = (u'agony prison terrible horrible nasty evil awful failure hurt poverty')\n",
    "\n",
    "results_across_grpLg = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, latino_names, Good)\n",
    "results_across_grpLb = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, latino_names, Bad)\n",
    "\n",
    "results_across_grpWg = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, white_names, Good)\n",
    "results_across_grpWb = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, white_names, Bad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(results_across_grpLg).to_csv('results_across_grpLg.csv')\n",
    "pd.DataFrame(results_across_grpLb).to_csv('results_across_grpLb.csv')\n",
    "#pd.DataFrame(results_across_grpWg).to_csv('results_across_grpWg.csv')\n",
    "#pd.DataFrame(results_across_grpWb).to_csv('results_across_grpWb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Garcia, agony, 0.07187948]\n",
      "[Garcia, prison, 0.10047299]\n",
      "[Garcia, terrible, 0.086038]\n",
      "[Garcia, horrible, 0.116017096]\n",
      "[Garcia, nasty, 0.124619946]\n",
      "[Garcia, evil, 0.096566945]\n",
      "[Garcia, awful, 0.07487768]\n",
      "[Garcia, failure, -0.019825682]\n",
      "[Garcia, hurt, 0.049357437]\n",
      "[Garcia, poverty, 0.0411705]\n",
      "[Martinez, agony, 0.053457517]\n",
      "[Martinez, prison, 0.107047275]\n",
      "[Martinez, terrible, 0.079622954]\n",
      "[Martinez, horrible, 0.10874506]\n",
      "[Martinez, nasty, 0.1448462]\n",
      "[Martinez, evil, 0.03268453]\n",
      "[Martinez, awful, 0.050672203]\n",
      "[Martinez, failure, -0.0366963]\n",
      "[Martinez, hurt, 0.1256816]\n",
      "[Martinez, poverty, 0.003540732]\n",
      "[Rodriguez, agony, 0.067162074]\n",
      "[Rodriguez, prison, 0.07793506]\n",
      "[Rodriguez, terrible, 0.07580609]\n",
      "[Rodriguez, horrible, 0.12247307]\n",
      "[Rodriguez, nasty, 0.093292184]\n",
      "[Rodriguez, evil, 0.07487546]\n",
      "[Rodriguez, awful, 0.060890593]\n",
      "[Rodriguez, failure, -0.06004275]\n",
      "[Rodriguez, hurt, 0.08448064]\n",
      "[Rodriguez, poverty, 0.04351765]\n",
      "[Lopez, agony, 0.13060817]\n",
      "[Lopez, prison, 0.10299801]\n",
      "[Lopez, terrible, 0.11933535]\n",
      "[Lopez, horrible, 0.16077387]\n",
      "[Lopez, nasty, 0.23929964]\n",
      "[Lopez, evil, 0.06276046]\n",
      "[Lopez, awful, 0.1243068]\n",
      "[Lopez, failure, -0.0060641575]\n",
      "[Lopez, hurt, 0.14631632]\n",
      "[Lopez, poverty, 0.01454119]\n",
      "[Hernandez, agony, 0.075373545]\n",
      "[Hernandez, prison, 0.04584858]\n",
      "[Hernandez, terrible, 0.047801714]\n",
      "[Hernandez, horrible, 0.079885095]\n",
      "[Hernandez, nasty, 0.050395872]\n",
      "[Hernandez, evil, 0.0027252194]\n",
      "[Hernandez, awful, 0.032503366]\n",
      "[Hernandez, failure, -0.079024844]\n",
      "[Hernandez, hurt, 0.065499134]\n",
      "[Hernandez, poverty, 0.003165155]\n",
      "[Gonzalez, agony, 0.06987728]\n",
      "[Gonzalez, prison, 0.03646826]\n",
      "[Gonzalez, terrible, 0.059317127]\n",
      "[Gonzalez, horrible, 0.09278941]\n",
      "[Gonzalez, nasty, 0.06916015]\n",
      "[Gonzalez, evil, 0.01466258]\n",
      "[Gonzalez, awful, 0.055845223]\n",
      "[Gonzalez, failure, -0.040850908]\n",
      "[Gonzalez, hurt, 0.07064159]\n",
      "[Gonzalez, poverty, 0.004324812]\n",
      "[Perez, agony, 0.097318225]\n",
      "[Perez, prison, 0.08003417]\n",
      "[Perez, terrible, 0.15633385]\n",
      "[Perez, horrible, 0.20912841]\n",
      "[Perez, nasty, 0.2079534]\n",
      "[Perez, evil, 0.06668877]\n",
      "[Perez, awful, 0.16503432]\n",
      "[Perez, failure, -0.023810029]\n",
      "[Perez, hurt, 0.19960882]\n",
      "[Perez, poverty, 0.029876906]\n",
      "[Sanchez, agony, 0.074841514]\n",
      "[Sanchez, prison, 0.0902253]\n",
      "[Sanchez, terrible, 0.14215678]\n",
      "[Sanchez, horrible, 0.18219608]\n",
      "[Sanchez, nasty, 0.2062488]\n",
      "[Sanchez, evil, 0.032658845]\n",
      "[Sanchez, awful, 0.13079983]\n",
      "[Sanchez, failure, 0.015143377]\n",
      "[Sanchez, hurt, 0.18992904]\n",
      "[Sanchez, poverty, 0.024918068]\n",
      "[Diaz, agony, 0.0974241]\n",
      "[Diaz, prison, 0.063224025]\n",
      "[Diaz, terrible, 0.11790957]\n",
      "[Diaz, horrible, 0.13259329]\n",
      "[Diaz, nasty, 0.16711278]\n",
      "[Diaz, evil, 0.083324134]\n",
      "[Diaz, awful, 0.11294978]\n",
      "[Diaz, failure, 0.015756156]\n",
      "[Diaz, hurt, 0.14486323]\n",
      "[Diaz, poverty, 0.062266313]\n",
      "[Ramirez, agony, 0.048707765]\n",
      "[Ramirez, prison, 0.102403834]\n",
      "[Ramirez, terrible, 0.06770174]\n",
      "[Ramirez, horrible, 0.1143242]\n",
      "[Ramirez, nasty, 0.092536755]\n",
      "[Ramirez, evil, 0.04069702]\n",
      "[Ramirez, awful, 0.060744997]\n",
      "[Ramirez, failure, -0.060262777]\n",
      "[Ramirez, hurt, 0.082516015]\n",
      "[Ramirez, poverty, -0.0036546958]\n"
     ]
    }
   ],
   "source": [
    "for row in results_across_grpLb: \n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##replication: rice \n",
    "\n",
    "#nlp = spacy.load('en_core_web_lg')\n",
    "latino_namesY = (u'Garcia Rodriguez Martinez Hernandez') #list of strings = input at present\n",
    "white_namesY = (u'Smith Johnson Williams Brown')\n",
    "GoodY = (u'wonderful pleasure glorious happy')\n",
    "BadY = (u'terrible horrible nasty awful')\n",
    "high_skill = (u'doctor engineer professor scientist')\n",
    "low_skill = (u'laborer busboy janitor maid')\n",
    "latino_nm = (u'Lopez Gonzalez Perez Sanchez')\n",
    "asian_nm = (u'Wang Liu Zhang  Lam')\n",
    "\n",
    "#results_across_grpLg2 = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, latino_nm, high_skill)\n",
    "#results_across_grpLb2 = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, latino_nm, low_skill)\n",
    "#\n",
    "#results_across_grpAg2 = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, asian_nm, high_skill)\n",
    "#results_across_grpAb2 = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, asian_nm, low_skill)\n",
    "\n",
    "results_across_grpWg2 = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, white_namesY, high_skill)\n",
    "results_across_grpWb2 = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, white_namesY, low_skill)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(results_across_grpLg2).to_csv('results_across_grpLg2.csv')\n",
    "#pd.DataFrame(results_across_grpLb2).to_csv('results_across_grpLb2.csv')\n",
    "#pd.DataFrame(results_across_grpAg2).to_csv('results_across_grpAg2.csv')\n",
    "#pd.DataFrame(results_across_grpAb2).to_csv('results_across_grpAb2.csv')\n",
    "\n",
    "\n",
    "pd.DataFrame(results_across_grpWg2).to_csv('results_across_grpWg2.csv')\n",
    "pd.DataFrame(results_across_grpWb2).to_csv('results_across_grpWb2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##replication: yale \n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "immigrant = (u'foreigner outsider immigrant nonnative migrant newcomer') #list of strings = input at present\n",
    "native = (u'native nonimmigrant homegrown citizen original local')\n",
    "positive = (u'lovely pleasure glorious beautiful marvelous wonderful joyful')\n",
    "negative = (u'humiliate terrible superb painful nasty horrible agony tragic')\n",
    "\n",
    "results_across_grpLp = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, immigrant, positive)\n",
    "results_across_grpLn = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, immigrant, negative)\n",
    "\n",
    "results_across_grpWp = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, native, positive)\n",
    "results_across_grpWn = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, native, negative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(results_across_grpLp).to_csv('results_across_grpLp.csv')\n",
    "pd.DataFrame(results_across_grpLn).to_csv('results_across_grpLn.csv')\n",
    "\n",
    "pd.DataFrame(results_across_grpWp).to_csv('results_across_grpWp.csv')\n",
    "pd.DataFrame(results_across_grpWn).to_csv('results_across_grpWn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#word pair similarities\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "Noncitizen = (u'illegals undocumented refugees immigrants foreigners') #list of strings = input at present\n",
    "Citizen = (u'citizens inhabitants locals natives residents') #list of strings = input at present\n",
    "# removed for graphing purposes, but still include in analysis [foreigners deportees nationalist]\n",
    "#w = (u'Mexican Iranian Afghanistan European Syrian Chinese Iraqi Egyptian Yemenese American ')\n",
    "protected = (u'secure protected shielded safe guarded')\n",
    "vulnerable = (u'unsafe unprotected vulnerable insecure susceptible')\n",
    "#z = (u'honest deceptive devious dishonest steal give share sneak hide cheat sincere smart dumb') #hide steal cheat (criminal, visiblity) #sincere\n",
    "results_citizen_protected = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, Citizen, protected)\n",
    "results_citizen_vulnerable = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, Citizen, vulnerable\n",
    "                                                                                  )\n",
    "\n",
    "results_noncitizen_protected = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, Noncitizen, protected)\n",
    "results_noncitizen_vulnerable = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, Noncitizen, vulnerable)\n",
    "\n",
    "#results_within_citizen = comparison_functions.Compare_Within_WordList_by_spaCyvectors(nlp, Citizen)\n",
    "#results_within_noncitizen = comparison_functions.Compare_Within_WordList_by_spaCyvectors(nlp, Noncitizen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[illegals, secure, 0.17569578]\n",
      "[illegals, protected, 0.15385419]\n",
      "[illegals, shielded, 0.05735599]\n",
      "[illegals, safe, 0.19242072]\n",
      "[illegals, guarded, 0.113468505]\n",
      "[undocumented, secure, 0.20192792]\n",
      "[undocumented, protected, 0.2235324]\n",
      "[undocumented, shielded, 0.099277884]\n",
      "[undocumented, safe, 0.21047887]\n",
      "[undocumented, guarded, 0.17493889]\n",
      "[refugees, secure, 0.21497013]\n",
      "[refugees, protected, 0.21161929]\n",
      "[refugees, shielded, 0.07783792]\n",
      "[refugees, safe, 0.22203165]\n",
      "[refugees, guarded, 0.1956736]\n",
      "[immigrants, secure, 0.20749956]\n",
      "[immigrants, protected, 0.19756925]\n",
      "[immigrants, shielded, 0.058356825]\n",
      "[immigrants, safe, 0.21633866]\n",
      "[immigrants, guarded, 0.16909179]\n",
      "[foreigners, secure, 0.24044341]\n",
      "[foreigners, protected, 0.23024325]\n",
      "[foreigners, shielded, 0.11716983]\n",
      "[foreigners, safe, 0.21149817]\n",
      "[foreigners, guarded, 0.28533807]\n",
      "[citizens, secure, 0.37087777]\n",
      "[citizens, protected, 0.38406697]\n",
      "[citizens, shielded, 0.15136184]\n",
      "[citizens, safe, 0.41430944]\n",
      "[citizens, guarded, 0.28316578]\n",
      "[inhabitants, secure, 0.18465237]\n",
      "[inhabitants, protected, 0.29783708]\n",
      "[inhabitants, shielded, 0.09693953]\n",
      "[inhabitants, safe, 0.20791428]\n",
      "[inhabitants, guarded, 0.30039737]\n",
      "[locals, secure, 0.19637845]\n",
      "[locals, protected, 0.23901995]\n",
      "[locals, shielded, 0.054133672]\n",
      "[locals, safe, 0.29207143]\n",
      "[locals, guarded, 0.3071932]\n",
      "[natives, secure, 0.107961155]\n",
      "[natives, protected, 0.22383182]\n",
      "[natives, shielded, 0.10241471]\n",
      "[natives, safe, 0.16047303]\n",
      "[natives, guarded, 0.26518178]\n",
      "[residents, secure, 0.27591774]\n",
      "[residents, protected, 0.26623046]\n",
      "[residents, shielded, 0.089008324]\n",
      "[residents, safe, 0.3831939]\n",
      "[residents, guarded, 0.23643981]\n",
      "[illegals, unsafe, 0.23531376]\n",
      "[illegals, unprotected, 0.16598533]\n",
      "[illegals, vulnerable, 0.2780936]\n",
      "[illegals, insecure, 0.18569574]\n",
      "[illegals, susceptible, 0.1397518]\n",
      "[undocumented, unsafe, 0.37038922]\n",
      "[undocumented, unprotected, 0.27362254]\n",
      "[undocumented, vulnerable, 0.40531582]\n",
      "[undocumented, insecure, 0.291312]\n",
      "[undocumented, susceptible, 0.15829068]\n",
      "[refugees, unsafe, 0.25639305]\n",
      "[refugees, unprotected, 0.17525625]\n",
      "[refugees, vulnerable, 0.42401525]\n",
      "[refugees, insecure, 0.21614996]\n",
      "[refugees, susceptible, 0.15335941]\n",
      "[immigrants, unsafe, 0.26598462]\n",
      "[immigrants, unprotected, 0.18184473]\n",
      "[immigrants, vulnerable, 0.37918016]\n",
      "[immigrants, insecure, 0.21930975]\n",
      "[immigrants, susceptible, 0.19169977]\n",
      "[foreigners, unsafe, 0.28071782]\n",
      "[foreigners, unprotected, 0.22415687]\n",
      "[foreigners, vulnerable, 0.3389759]\n",
      "[foreigners, insecure, 0.2998808]\n",
      "[foreigners, susceptible, 0.21587782]\n",
      "[citizens, unsafe, 0.3113319]\n",
      "[citizens, unprotected, 0.22797062]\n",
      "[citizens, vulnerable, 0.46823627]\n",
      "[citizens, insecure, 0.25190416]\n",
      "[citizens, susceptible, 0.26054424]\n",
      "[inhabitants, unsafe, 0.22012244]\n",
      "[inhabitants, unprotected, 0.18875809]\n",
      "[inhabitants, vulnerable, 0.34329662]\n",
      "[inhabitants, insecure, 0.18082467]\n",
      "[inhabitants, susceptible, 0.2402274]\n",
      "[locals, unsafe, 0.2732856]\n",
      "[locals, unprotected, 0.16936211]\n",
      "[locals, vulnerable, 0.28750065]\n",
      "[locals, insecure, 0.21027423]\n",
      "[locals, susceptible, 0.17196007]\n",
      "[natives, unsafe, 0.1896773]\n",
      "[natives, unprotected, 0.21826963]\n",
      "[natives, vulnerable, 0.3219496]\n",
      "[natives, insecure, 0.2059248]\n",
      "[natives, susceptible, 0.24290772]\n",
      "[residents, unsafe, 0.32294798]\n",
      "[residents, unprotected, 0.15300545]\n",
      "[residents, vulnerable, 0.3860157]\n",
      "[residents, insecure, 0.15626764]\n",
      "[residents, susceptible, 0.19689357]\n"
     ]
    }
   ],
   "source": [
    "for row in results_noncitizen_protected: \n",
    "    print(row)\n",
    "for row in results_citizen_protected: \n",
    "    print(row)\n",
    "for row in results_noncitizen_vulnerable: \n",
    "    print(row)\n",
    "for row in results_citizen_vulnerable: \n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(results_citizen_protected).to_csv('results_citizen_protected.csv')\n",
    "pd.DataFrame(results_citizen_vulnerable).to_csv('results_citizen_vulnerable.csv')\n",
    "\n",
    "pd.DataFrame(results_noncitizen_protected).to_csv('results_noncitizen_protected.csv')\n",
    "pd.DataFrame(results_noncitizen_vulnerable).to_csv('results_noncitizen_vulnerable.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "Noncitizen = (u'illegals undocumented refugees immigrants foreigners') #list of strings = input at present\n",
    "Citizen = (u'citizens inhabitants locals natives residents') #list of strings = input at present\n",
    "# removed for graphing purposes, but still include in analysis [foreigners deportees nationalist]\n",
    "#w = (u'Mexican Iranian Afghanistan European Syrian Chinese Iraqi Egyptian Yemenese American ')\n",
    "protected = (u'go walk enter come move')\n",
    "vulnerable = (u'steal cheat hide harm burden')\n",
    "#z = (u'honest deceptive devious dishonest steal give share sneak hide cheat sincere smart dumb') #hide steal cheat (criminal, visiblity) #sincere\n",
    "results_citizen_protected = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, Citizen, protected)\n",
    "results_citizen_vulnerable = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, Citizen, vulnerable\n",
    "                                                                                  )\n",
    "\n",
    "results_noncitizen_protected = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, Noncitizen, protected)\n",
    "results_noncitizen_vulnerable = comparison_functions.CompareWordLists_by_spaCyvectors(nlp, Noncitizen, vulnerable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(results_citizen_protected).to_csv('results_citizen_literal.csv')\n",
    "pd.DataFrame(results_citizen_vulnerable).to_csv('results_citizen_metaphor.csv')\n",
    "\n",
    "pd.DataFrame(results_noncitizen_protected).to_csv('results_noncitizen_literal.csv')\n",
    "pd.DataFrame(results_noncitizen_vulnerable).to_csv('results_noncitizen_metaphor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
